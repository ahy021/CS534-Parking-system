import warnings
warnings.filterwarnings("ignore")

import pandas as pd
import lightning.pytorch as pl
from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer, Baseline
from pytorch_forecasting.data import GroupNormalizer
from pytorch_forecasting.metrics import MAE
from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters
from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor
from lightning.pytorch.loggers import TensorBoardLogger
from optuna.integration import PyTorchLightningPruningCallback
import optuna

from sklearn.metrics import log_loss, brier_score_loss, roc_auc_score

def main():
    # Load and preprocess data
    data = pd.read_csv("Paid_Parking__Last_48_Hours_.csv")
    data["OccupancyDateTime"] = pd.to_datetime(data["OccupancyDateTime"], format="%m/%d/%Y %I:%M:%S %p")
    data = data.sort_values(["BlockfaceName", "OccupancyDateTime"])
    data["time_idx"] = data.groupby("BlockfaceName").cumcount()
    data["hour"] = data["OccupancyDateTime"].dt.hour
    data["weekday"] = data["OccupancyDateTime"].dt.weekday
    data.rename(columns={"PaidOccupancy": "occupancy"}, inplace=True)

    # Binary classification: 1 if occupied (> 0), else 0
    data["occupancy_binary"] = (data["occupancy"] > 0).astype(int)

    categorical_cols = [
        "SideOfStreet", "ParkingTimeLimitCategory",
        "PaidParkingArea", "PaidParkingSubArea", "ParkingCategory"
    ]
    data[categorical_cols] = data[categorical_cols].astype(str)

    max_prediction_length = 6  # Assuming 5-min intervals â†’ 30 minutes
    max_encoder_length = 24
    training_cutoff = data["time_idx"].max() - max_prediction_length

    training = TimeSeriesDataSet(
        data[lambda x: x.time_idx <= training_cutoff],
        time_idx="time_idx",
        target="occupancy_binary",
        group_ids=["BlockfaceName"],
        min_encoder_length=max_encoder_length // 2,
        max_encoder_length=max_encoder_length,
        min_prediction_length=1,
        max_prediction_length=max_prediction_length,
        static_categoricals=categorical_cols,
        static_reals=["ParkingSpaceCount"],
        time_varying_known_categoricals=[],
        time_varying_known_reals=["time_idx", "hour", "weekday"],
        time_varying_unknown_categoricals=[],
        time_varying_unknown_reals=["occupancy_binary"],
        target_normalizer=None,  # Important for classification (don't normalize binary)
        add_relative_time_idx=True,
        add_target_scales=False,
        add_encoder_length=True,
    )

    validation = TimeSeriesDataSet.from_dataset(
        training,
        data,
        predict=True,
        stop_randomization=True
    )

    batch_size = 64
    train_dataloader = training.to_dataloader(train=True, batch_size=batch_size)
    val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 5)

    # Fix seed
    pl.seed_everything(42)

    optuna.logging.set_verbosity(optuna.logging.INFO)

    # Run hyperparameter tuning
    print("Running hyperparameter tuning...")
    best_model_path, best_hyperparams = optimize_hyperparameters(
        train_dataloaders=train_dataloader,
        val_dataloaders=val_dataloader,
        model_path="tuned_model",
        max_epochs=10,
        n_trials=3,
        timeout=3600,
        gradient_clip_val_range=(0.01, 1.0),
        hidden_size_range=(8, 32),
        hidden_continuous_size_range=(8, 32),
        attention_head_size_range=(1, 4),
        learning_rate_range=(1e-4, 0.1),
        dropout_range=(0.1, 0.3),
        trainer_kwargs=dict(
            accelerator="cpu",  # Change to "gpu" if you have one
            logger=TensorBoardLogger("lightning_logs", name="tuning"),
            enable_progress_bar=False
        ),
    )
    print("Best hyperparameters:", best_hyperparams)

    # Load the best model
    best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)

    # Predict on validation with raw outputs for classification metrics
    raw_preds, index = best_tft.predict(val_dataloader, mode="raw", return_y=True, return_index=True)

    # Get probabilities and true binary targets
    probs = raw_preds["prediction"].detach().cpu().numpy().flatten()
    true = index["decoder_target"].detach().cpu().numpy().flatten()

    # Ensure alignment
    if len(probs) != len(true):
        min_len = min(len(probs), len(true))
        probs = probs[:min_len]
        true = true[:min_len]

    # Evaluation metrics
    print("Log Loss:", log_loss(true, probs))
    print("Brier Score:", brier_score_loss(true, probs))
    print("ROC-AUC Score:", roc_auc_score(true, probs))

    # Save final model
    best_tft.save("best_tft_model.pt")

if __name__ == "__main__":
    main()
